reward_func,learning_rate_decay_rate,end_e,h_regu_frac,save_max_to_keep,max_interactions,test_mode,rmsprop_decay,model_dir,agent_num,init_e,rwd_e_para,sharedNet_type,is_learning_rate_decay_staircase,learning_rate_decay_steps,isNoisyNetEval_rmNoise,train_freq,is_greedy_policy,debug_log_prob,window_len,eval_epi_num,output,eval_freq,activation,dropout_prob,decay_steps,action_repeat_n,rmsprop_momet,eval_act_func,num_threads,isNoisyNet,model_type,clip_norm,state_dim,train_act_func,save_scope,weight_initer,forecast_dim,job_mode,check_args_only,metric_func,rwd_p_para,rmsprop_epsil,learning_rate,h_decay_bounds,p_loss_frac,save_freq,env,model_param,gamma,action_space,raw_state_prcs_func,v_loss_frac,violation_penalty_scl,test_env,is_warm_start
cslDxCool_1,0.9,0.0,[0.1],5,10000000,Multiple,0.99,None,5,0.0,1.0,Dense,False,100000,False,5,False,0.0005,6,1,a3c-res-v0.1,250000,tanh/relu,0.0,1000000,1,0.0,cslDxActCool_1,16,False,lstm,5.0,49,cslDxActCool_1,all,glorot_uniform,0,Train,True,cslDxCool_1,1.0,1e-10,0.001,[],1.0,500000,Model1-Cool-v1,"[64, 4, 64, 4]",0.99,cslDxCool_1,cslDx_1,0.5,10.0,Model1-Test-Cool-v1,False
